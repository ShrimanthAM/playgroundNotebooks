{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a Spark GraphX program to perform few analysis steps for sample US airports. Conduct the following steps:\n",
    "Steps & Hints: \n",
    "1.\tGenerate a new RDD containing few selected US airport information, such as: (“BWI”, “Baltimore Washington Airport”, “JFK”, “NYC Airport”, “MIA”, “Miami Airport”, “LAX”, “Los Angeles Airport”, etc.)\n",
    "2.\tLimit your airport selection to 10 airports\n",
    "3.\tGenerate random data for flights between two random airports (selected from the RDD above). Random data generated can be in the form (src, dst, flight number), (“BWI”, “LAX”, “1552”), etc.\n",
    "4.\tYou may use similar algorithm from the previous homework, make sure you generate 200+ flights (if you have a randomize function that generates one flight data information, then call the function 200 times)\n",
    "5.\tGenerate the relationship graph\n",
    "6.\tFind the airport with the largest number of departure flight\n",
    "7.\tFind the airport with the largest number of arriving flight\n",
    "8.\tFind the busiest airport\n",
    "9.\tNote: Illustrate your work and display your results (to get full grade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "#import spark\n",
    "from pyspark import SparkContext\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " rdd=sc.textFile(\"AirportCode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BWI,Baltimore Airport',\n",
       " 'IAD,International Airport of Dulles',\n",
       " 'NYA,NewYork Airport',\n",
       " 'FIA,Florida International Airport',\n",
       " 'INA,Indiana Airport',\n",
       " 'VIA,Virginia International Airport',\n",
       " 'KSA,Kansas State Airport',\n",
       " 'TIA,Texas International Airport',\n",
       " 'PNA,Pennsylvania Airport',\n",
       " 'NJA,NewJersey Airport']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedRdd= rdd.map(lambda x:x.split(\";\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['BWI,Baltimore Airport'],\n",
       " ['IAD,International Airport of Dulles'],\n",
       " ['NYA,NewYork Airport'],\n",
       " ['FIA,Florida International Airport'],\n",
       " ['INA,Indiana Airport'],\n",
       " ['VIA,Virginia International Airport'],\n",
       " ['KSA,Kansas State Airport'],\n",
       " ['TIA,Texas International Airport'],\n",
       " ['PNA,Pennsylvania Airport'],\n",
       " ['NJA,NewJersey Airport']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappedRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = mappedRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['BWI,Baltimore Airport'],\n",
       " ['IAD,International Airport of Dulles'],\n",
       " ['NYA,NewYork Airport'],\n",
       " ['FIA,Florida International Airport'],\n",
       " ['INA,Indiana Airport'],\n",
       " ['VIA,Virginia International Airport'],\n",
       " ['KSA,Kansas State Airport'],\n",
       " ['TIA,Texas International Airport'],\n",
       " ['PNA,Pennsylvania Airport'],\n",
       " ['NJA,NewJersey Airport']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappedRdd.take(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List = ['BWI','IAD','NYA','FIA','INA','VIA','KSA','TIA','PNA','NJA']\n",
    "lis =['Journey']\n",
    "for n in range(200):\n",
    "    df1.append({'FlightNo': ((randint(1000, 9999))),\n",
    "              'Source' : random.choice(list1),\n",
    "               'Destination' : random.choice(list1),\n",
    "                'Relationship':random.choice(lis)\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination</th>\n",
       "      <th>FlightNo</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[TIA,Texas International Airport]</td>\n",
       "      <td>1517</td>\n",
       "      <td>Journey</td>\n",
       "      <td>[FIA,Florida International Airport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[BWI,Baltimore Airport]</td>\n",
       "      <td>7662</td>\n",
       "      <td>Journey</td>\n",
       "      <td>[INA,Indiana Airport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[VIA,Virginia International Airport]</td>\n",
       "      <td>9642</td>\n",
       "      <td>Journey</td>\n",
       "      <td>[INA,Indiana Airport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[IAD,International Airport of Dulles]</td>\n",
       "      <td>5177</td>\n",
       "      <td>Journey</td>\n",
       "      <td>[PNA,Pennsylvania Airport]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[KSA,Kansas State Airport]</td>\n",
       "      <td>9704</td>\n",
       "      <td>Journey</td>\n",
       "      <td>[INA,Indiana Airport]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Destination  FlightNo Relationship  \\\n",
       "0      [TIA,Texas International Airport]      1517      Journey   \n",
       "1                [BWI,Baltimore Airport]      7662      Journey   \n",
       "2   [VIA,Virginia International Airport]      9642      Journey   \n",
       "3  [IAD,International Airport of Dulles]      5177      Journey   \n",
       "4             [KSA,Kansas State Airport]      9704      Journey   \n",
       "\n",
       "                                Source  \n",
       "0  [FIA,Florida International Airport]  \n",
       "1                [INA,Indiana Airport]  \n",
       "2                [INA,Indiana Airport]  \n",
       "3           [PNA,Pennsylvania Airport]  \n",
       "4                [INA,Indiana Airport]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover,Word2Vec,StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import re\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyspark\n",
      "Version: 2.4.5\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: c:\\users\\pushy\\anaconda3\\lib\\site-packages\n",
      "Requires: py4j\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer,StopWordsRemover,Word2Vec\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from os import path, getcwd\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('SentimentClassifierCreationWithSparkML').getOrCreate()\n",
    "\n",
    "'''\n",
    "Unpacking Archive data file \n",
    "'''\n",
    "#shutil.unpack_archive('training.1600000.processed.noemoticon.csv.tar.gz', 'datasets')\n",
    "#print('Archive file unpacked successfully.')\n",
    "\n",
    "df3 = spark.read.csv('data.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of records in df after deleting duplicate and null records :  201\n"
     ]
    }
   ],
   "source": [
    "print('Total Number of records in df after deleting duplicate and null records : ',df3.count())\n",
    "df3 = df3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----+-------+--------------------+\n",
      "|_c0|                 _c1| _c2|    _c3|                 _c4|\n",
      "+---+--------------------+----+-------+--------------------+\n",
      "|  0|['TIA,Texas Inter...|1517|Journey|['FIA,Florida Int...|\n",
      "|  1|['BWI,Baltimore A...|7662|Journey|['INA,Indiana Air...|\n",
      "|  2|['VIA,Virginia In...|9642|Journey|['INA,Indiana Air...|\n",
      "|  3|['IAD,Internation...|5177|Journey|['PNA,Pennsylvani...|\n",
      "|  4|['KSA,Kansas Stat...|9704|Journey|['INA,Indiana Air...|\n",
      "+---+--------------------+----+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------+-------------+--------------------+\n",
      "|Index|         Destination|FlightNo|Relationships|              Source|\n",
      "+-----+--------------------+--------+-------------+--------------------+\n",
      "|    0|['TIA,Texas Inter...|    1517|      Journey|['FIA,Florida Int...|\n",
      "|    1|['BWI,Baltimore A...|    7662|      Journey|['INA,Indiana Air...|\n",
      "|    2|['VIA,Virginia In...|    9642|      Journey|['INA,Indiana Air...|\n",
      "|    3|['IAD,Internation...|    5177|      Journey|['PNA,Pennsylvani...|\n",
      "|    4|['KSA,Kansas Stat...|    9704|      Journey|['INA,Indiana Air...|\n",
      "+-----+--------------------+--------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Destination\tFlightNo\tSource\n",
    "df3 = df3.withColumnRenamed('_c0','Index').withColumnRenamed('_c1','Destination').withColumnRenamed('_c2','FlightNo').withColumnRenamed('_c3','Relationships').withColumnRenamed('_c4','Source')\n",
    "df3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType\n",
    "from pyspark.sql.types import StructField\n",
    "from pyspark.sql.types import StringType\n",
    "#sqlContext = SQLContext(sc)\n",
    "#schema = StructType([StructField(str(i), StringType()) for i in range(10)])\n",
    "\n",
    "#df = sqlContext.createDataFrame(mappedRdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(mappedRdd, \"toDF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession(sc)\n",
    "hasattr(mappedRdd, \"toDF\")\n",
    "## True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=mappedRdd.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                  _1|\n",
      "+--------------------+\n",
      "|BWI,Baltimore Air...|\n",
      "|IAD,International...|\n",
      "| NYA,NewYork Airport|\n",
      "|FIA,Florida Inter...|\n",
      "| INA,Indiana Airport|\n",
      "|VIA,Virginia Inte...|\n",
      "|KSA,Kansas State ...|\n",
      "|TIA,Texas Interna...|\n",
      "|PNA,Pennsylvania ...|\n",
      "|NJA,NewJersey Air...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            Airports|\n",
      "+--------------------+\n",
      "|BWI,Baltimore Air...|\n",
      "|IAD,International...|\n",
      "| NYA,NewYork Airport|\n",
      "|FIA,Florida Inter...|\n",
      "| INA,Indiana Airport|\n",
      "|VIA,Virginia Inte...|\n",
      "|KSA,Kansas State ...|\n",
      "|TIA,Texas Interna...|\n",
      "|PNA,Pennsylvania ...|\n",
      "|NJA,NewJersey Air...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.withColumnRenamed('_1','Airports')\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install graphframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import GraphFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from pyspark.sql.functions import col, lit, when\n",
    "from graphframes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "\n",
    "# Create Vertices (airports) and Edges (flights)\n",
    "\n",
    "tripEdges = df3.select(\"Index\",\"Destination\",\"FlightNo\",\"Relationships\",\"Source\")\n",
    "tripVertices = data.select(\"Airports\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tripEdges = departureDelays.select(“tripid”, “delay”, “src”, “dst”, “city_dst”, “state_dst”)\n",
    "# This GraphFrame builds upon the vertices and edges based on our trips (flights)\n",
    "\n",
    "tripGraph = GraphFrame(tripVertices, tripEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print “Airports: %d” % tripGraph.vertices.count()\n",
    "\n",
    "#print “Trips: %d” % tripGraph.edges.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wget https://dl.bintray.com/spark-packages/maven/graphframes/graphframes/0.7.0-spark2.4-s_2.11/graphframes-0.7.0-spark2.4-s_2.11.jar -P /path-to-spark/spark/jars/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"HELK Graphs\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --user pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " !pip install --user --upgrade --no-deps pixiedust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pixiedust.packageManager import PackageManager\n",
    "pkg=PackageManager()\n",
    "pkg.installPackage(\"graphframes:graphframes:0\")\n",
    "pkg.printAllPackages()\n",
    " \n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the display module\n",
    "from pixiedust.display import *\n",
    "#import the Graphs example\n",
    "#from graphframes.examples import Graphs\n",
    "#create the friends example graph\n",
    "#g=Graphs(sqlContext).friends()\n",
    "#use the pixiedust display\n",
    "#display(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.orderBy(\"Source\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.orderBy(\"Destination\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.groupBy('Destination').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data = df3.groupBy(\"Source\")\n",
    "group_data.agg({'Destination':'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_data1 = df3.groupBy(\"Destination\")\n",
    "group_data1.agg({'Source':'count'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3.agg(corr(\"Destination\", \"Source\").alias('correlation')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Source=group_data1.agg({'Source':'count'}).toPandas()\n",
    "df_Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2=df_Source.rename(columns={'Destination':'All','count(Source)':'Count'})\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=['INA','IAD','VIA','PNA','KSA','BWI','NJA','TIA','FIA','NYA']\n",
    "rect=df_Source.loc[:,['Destination','count(Source)']].plot.bar(figsize=(10,7), fontsize=13)\n",
    "plt.xticks(range(10),['INA','IAD','VIA','PNA','KSA','BWI','NJA','TIA','FIA','NYA'])\n",
    "plt.xlabel('Destinations',fontsize=18) \n",
    "plt.ylabel('sum of dstination to sources', fontsize=18) \n",
    "plt.title('Airport with the largest number of arrival flight', fontsize=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Dest=group_data.agg({'Destination':'count'}).toPandas()\n",
    "d1=df_Dest.rename(columns={'Source':'All','count(Destination)':'Count'})\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x=['INA','IAD','VIA','PNA','KSA','BWI','NJA','TIA','FIA','NYA']\n",
    "rect=df_Dest.loc[:,['Source','count(Destination)']].plot.bar(figsize=(10,7), fontsize=13)\n",
    "plt.xticks(range(10),['INA','IAD','VIA','PNA','KSA','BWI','NJA','TIA','FIA','NYA'])\n",
    "plt.xlabel('Sources',fontsize=18) \n",
    "plt.ylabel('sum of Source to destination', fontsize=18) \n",
    "plt.title('Airport with the largest number of Departure', fontsize=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Dest.rename(columns={'Source':'Source','count(Destination)':'Count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.merge(d1, d2, on='All',how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['BusyCount'] = dff['Count_x'] + dff['Count_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=['INA','IAD','VIA','PNA','KSA','BWI','NJA','TIA','FIA','NYA']\n",
    "rect=dff.loc[:,['BusyCount']].plot.bar(figsize=(10,7), fontsize=13)\n",
    "plt.xticks(range(10),['INA','IAD','VIA','PNA','KSA','BWI','NJA','TIA','FIA','NYA'])\n",
    "plt.xlabel('Airports',fontsize=18) \n",
    "plt.ylabel('Count of arrivals and departures', fontsize=18) \n",
    "plt.title('The busiest airport', fontsize=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_groups = 10\n",
    "fig, ax = plt.subplots(figsize=(13,5))\n",
    "bar_width = 0.20\n",
    "opacity = 0.8\n",
    "index = np.arange(n_groups)\n",
    "\n",
    "rects1 = plt.bar(index - bar_width, dff['Count_x'], bar_width,alpha=opacity,color='b',label='Sources')\n",
    "rects2 = plt.bar(index, dff['Count_y'], bar_width,alpha=opacity,color='g',label='Destinations')\n",
    "rects3 = plt.bar(index + bar_width, dff['BusyCount'], bar_width,alpha=opacity,color='r',label='Busy Airport')\n",
    "plt.xlabel('Airports', fontsize=18)\n",
    "plt.ylabel('Total Counts', fontsize=18)\n",
    "plt.title('COunts of Departure Arrival and busy airport',fontsize=23)\n",
    "plt.xticks(index + bar_width, ('INA','IAD','VIA','PNA','KSA','BWI','NJA','TIA','FIA','NYA'))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
